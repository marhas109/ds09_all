{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7IWweaN7DDg"
   },
   "source": [
    "## Part 1: Text Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sko0fD4j8PXe"
   },
   "source": [
    "Let's import the required libraries and load our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INc1xMPd6_ag"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# For text preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset loading\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load a subset of the 20 Newsgroups dataset\n",
    "categories = ['comp.graphics', 'rec.autos', 'sci.space', 'talk.politics.misc']\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories, random_state=42)\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,\n",
    "    'category': [newsgroups.target_names[target] for target in newsgroups.target]\n",
    "})\n",
    "\n",
    "# Preview the data\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(\"\\nSample document:\")\n",
    "print(df['text'][10][:500])  # Print first 500 characters of a sample document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-sI1_LY8KuA"
   },
   "source": [
    "### Step 1: Basic Data Exploration\n",
    "Let's examine the length characteristics of our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNwzYpF_8U_Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['post_length'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "df['sentence_count'] =df['text'].apply(lambda x: len(sent_tokenize(str(x))))\n",
    "\n",
    "# Create visualizations to understand the data\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['word_count'], bins=20)\n",
    "plt.title('Distribution of Newsgroup Post Lengths By Word')\n",
    "plt.xlabel('Word Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=\"category\", y='word_count', data=df)\n",
    "plt.title('Post Length by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69XtNx_98hco"
   },
   "source": [
    "### Step 2: Text Cleaning and Preprocessing Function\n",
    "Let's create a comprehensive text preprocessing function that incorporates all the techniques we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_tokens):\n",
    "    # Convert to lowercase\n",
    "    text_tokens = [text_token.lower() for text_token in text_tokens]\n",
    "        \n",
    "    cleaned = []\n",
    "    # Remove punctuation but keep numbers\n",
    "    for text_token in text_tokens:    \n",
    "        no_punc = re.sub(r'[^\\w\\s]', '', text_token)\n",
    "     \n",
    "        if no_punc and not no_punc.isspace():\n",
    "            cleaned.append(no_punc)\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# remove stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "    \n",
    "    # tag with parts of speech\n",
    "    tokens_tagged = pos_tag(tokens)\n",
    "      \n",
    "    # convert to WordNet POS tags\n",
    "    pos_tokens = [(word[0], get_wordnet_pos(word[1])) for word in tokens_tagged]\n",
    "        \n",
    "    # lemmatize with POS tags\n",
    "    lemmatized = [lemmatizer.lemmatize(word[0], word[1]) for word in pos_tokens]\n",
    "        \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_clean = df['tokens'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_clean = initial_clean.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_clean = step2_clean.apply(lemmatize_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7H5rdOI8kJZ"
   },
   "outputs": [],
   "source": [
    "# Sentence and word tokenization\n",
    "df['sentences'] = df['text'].apply(sent_tokenize)\n",
    "df['tokens'] = df['text'].apply(word_tokenize)\n",
    "\n",
    "def cleaning_preprocessing_pipeline(text):\n",
    "    # initial cleaning of word tokens\n",
    "    def clean_text(text_tokens):\n",
    "        \"\"\"\n",
    "        1. Converts to lowercase\n",
    "        2. Removes HTML tags and special characters\n",
    "        3. Handle common \n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text_tokens = [text_token.lower() for text_token in text_tokens]\n",
    "        \n",
    "        cleaned = []\n",
    "        # Remove punctuation but keep numbers\n",
    "        for text_token in text_tokens:    \n",
    "            no_punc = re.sub(r'[^\\w\\s]', '', text_token)\n",
    "        \n",
    "            if no_punc and not no_punc.isspace():\n",
    "                cleaned.append(no_punc)\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    # get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # remove stopwords\n",
    "    def remove_stopwords(tokens):\n",
    "        return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # helper function for lemmatization with POS tagging\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        \"\"\"\n",
    "        Convert NLTK POS tags to WordNet POS tags\n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    # lemmatize\n",
    "    def lemmatize_tokens(tokens):\n",
    "        # tag with parts of speech\n",
    "        tokens_tagged = pos_tag(tokens)\n",
    "        \n",
    "        # convert to WordNet POS tags\n",
    "        pos_tokens = [(word[0], get_wordnet_pos(word[1])) for word in tokens_tagged]\n",
    "        \n",
    "        # lemmatize with POS tags\n",
    "        lemmatized = [lemmatizer.lemmatize(word[0], word[1]) for word in pos_tokens]\n",
    "        \n",
    "        return lemmatized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IODTKVf-8oqg"
   },
   "source": [
    "### Step 3: Apply Preprocessing and Analyze Results\n",
    "Now let's apply our preprocessing function to the dataset and examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_p9JjZM8peG"
   },
   "outputs": [],
   "source": [
    "# apply cleaning pipline to all text\n",
    "df['processed_tokens'] = df['tokens'].apply(cleaning_preprocessing_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG61Yron8-Lj"
   },
   "source": [
    "### Step 4: Token Frequency Analysis\n",
    "Let's analyze the most common words in each category after preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKO1A7mD8_M2"
   },
   "outputs": [],
   "source": [
    "# Assign the count of unique word tokens across all reviews\n",
    "lst_tokens = df['tokens']\n",
    "lst_words = [item for sublist in lst_tokens for item in sublist]\n",
    "\n",
    "dict_all_tokens = {}\n",
    "for word in lst_words:\n",
    "    if word in dict_all_tokens:\n",
    "        dict_all_tokens[word] += 1\n",
    "    else:\n",
    "        dict_all_tokens[word] = 1\n",
    "\n",
    "all_tokens = [(token, count) for token, count in dict_all_tokens.items()]\n",
    "unique_token_count_pre = len(all_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2TXrD659FLk"
   },
   "source": [
    "### Step 5: N-gram Analysis\n",
    "Let's go beyond single words and look at common bigrams and trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo6OdiCK9KcO"
   },
   "outputs": [],
   "source": [
    "# Function to generate bigrams and trigrams\n",
    "def generate_ngrams(tokens, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams from a list of tokens\n",
    " \n",
    "    Parameters:\n",
    "    tokens (list): List of tokens\n",
    "    n (int): Size of n-grams to generate\n",
    "        \n",
    "    Returns:\n",
    "    list: List of n-grams as tuples\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for n in n:\n",
    "        result[f'{n}-grams'] = list(ngrams(tokens, n))\n",
    "    return result\n",
    "\n",
    "# Generate bigrams and trigrams - hint - apply lamdba function\n",
    "b_n = [2]\n",
    "t_n = [3]\n",
    "\n",
    "df['bigrams'] = df['lemmatized_tokens'].apply(lambda x: generate_ngrams(x, b_n))\n",
    "df['trigrams'] = df['lemmatized_tokens'].apply(lambda x: generate_ngrams(x, t_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj87c0Bw9PIk"
   },
   "source": [
    "## Part 2: Time Series Analysis and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVIegiiq9ws3"
   },
   "source": [
    "### Step 1: Data Loading and Initial Exploration\n",
    "First, let's load the S&P 500 historical data and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "llNFNFg69OwX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsaplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_acf, plot_pacf\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myfinance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Suppress warnings for cleaner output\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme()\n",
    "\n",
    "# Download S&P 500 data for the last 10 years\n",
    "sp500 = yf.download('^GSPC', start='2013-01-01', end='2022-12-31')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"S&P 500 Dataset:\")\n",
    "print(sp500.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "print(sp500.info())\n",
    "\n",
    "# Calculate basic summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(sp500['Close'].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(sp500.isnull().sum())\n",
    "\n",
    "# Plot the closing price\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sp500.index, sp500['Close'])\n",
    "plt.title('S&P 500 Closing Price (2013-2022)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select the closing price as our primary time series for analysis\n",
    "ts_data = sp500['Close']\n",
    "print(\"\\nSelected time series shape:\", ts_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4T_TCL7-DPB"
   },
   "source": [
    "### Step 2: Time Series Characteristics and Visualization\n",
    "Let's analyze the characteristics of the time series through various visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF5KM7DQ-F6g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF8raTqP-Hoy"
   },
   "source": [
    "### Step 3: Stationarity Testing and Transformation\n",
    "Now, let's test for stationarity using the Dickey-Fuller test and apply transformations to make the data stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggXs_3xT-URk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WoUfIbO-ecx"
   },
   "source": [
    "### Step 4: Time Series Decomposition\n",
    "Let's decompose our time series into trend, seasonal, and residual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfOOyeB8-gkN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFP_Ep8r-jrE"
   },
   "source": [
    "### Step 5: Autocorrelation Analysis\n",
    "Now, let's analyze the autocorrelation structure of our stationary series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ume0Z4pe-kzD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhoT_KYX-oor"
   },
   "source": [
    "### Step 6: Time Series Modeling\n",
    "Finally, let's build and evaluate time series models based on our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmCppbtg-pPs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mEB--Gk-t3L"
   },
   "source": [
    "## Part 3: Neural Networks Implementation and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjG1Y1WP-uwG"
   },
   "source": [
    "### Step 1: Load libraries and prepare the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iSGaPSFh-vmw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits dataset: 1797 samples, 64 features\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# For deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# For PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load Digits dataset for classification\n",
    "digits = load_digits()\n",
    "X_digits = digits.data / 16\n",
    "y_digits = digits.target\n",
    "\n",
    "\n",
    "# Display sample digits\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits.images[i], cmap='gray')\n",
    "    plt.title(f'Digit: {digits.target[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print information about dataset\n",
    "print(f\"Digits dataset: {X_digits.shape[0]} samples, {X_digits.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits_df = pd.DataFrame(X_digits)\n",
    "y_digits_df = pd.DataFrame(y_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_digits_nan_count = X_digits_df.isnull().any(axis=1).sum()\n",
    "y_digits_nan_count = y_digits_df.isnull().any(axis=1).sum()\n",
    "X_digits_nan_count, y_digits_nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEo8zEVFAkKX"
   },
   "source": [
    "### Step 2: Preprocess data for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qZolykL6Amvs"
   },
   "outputs": [],
   "source": [
    "# 1st split: 0.8 train+val 0.2 test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_digits, y_digits, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2nd split: 0.75 train 0.25 val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_digits, y_digits, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qpU6AYuA9vW"
   },
   "source": [
    "### Step 3: Build a basic MLP for digits classification using TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qoo0lEvBA_lb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8681 - accuracy: 0.5590 - val_loss: 1.2954 - val_accuracy: 0.7917\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8958 - accuracy: 0.8523 - val_loss: 0.5562 - val_accuracy: 0.8833\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.9035 - val_loss: 0.3295 - val_accuracy: 0.9222\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.9347 - val_loss: 0.2371 - val_accuracy: 0.9417\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9532 - val_loss: 0.2028 - val_accuracy: 0.9361\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9547 - val_loss: 0.1677 - val_accuracy: 0.9472\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9621 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9785 - val_loss: 0.1351 - val_accuracy: 0.9694\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9718 - val_loss: 0.1258 - val_accuracy: 0.9667\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9696 - val_loss: 0.1141 - val_accuracy: 0.9667\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9844 - val_loss: 0.1139 - val_accuracy: 0.9667\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9822 - val_loss: 0.1068 - val_accuracy: 0.9806\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9874 - val_loss: 0.0975 - val_accuracy: 0.9694\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9881 - val_loss: 0.1053 - val_accuracy: 0.9722\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9918 - val_loss: 0.0991 - val_accuracy: 0.9667\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9911 - val_loss: 0.0932 - val_accuracy: 0.9750\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9918 - val_loss: 0.0973 - val_accuracy: 0.9694\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9941 - val_loss: 0.0924 - val_accuracy: 0.9750\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9926 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9963 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9955 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9948 - val_loss: 0.0910 - val_accuracy: 0.9694\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9948 - val_loss: 0.0871 - val_accuracy: 0.9750\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9970 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9978 - val_loss: 0.0952 - val_accuracy: 0.9750\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9948 - val_loss: 0.0881 - val_accuracy: 0.9750\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 0.0878 - val_accuracy: 0.9833\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9978 - val_loss: 0.0859 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9978 - val_loss: 0.0881 - val_accuracy: 0.9806\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9985 - val_loss: 0.0846 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(64,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93T-ARKaBGqg"
   },
   "source": [
    "### Step 4: Implement the digits classification model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f1Pn60fkBKjn"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)  # Long tensor for classification\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_classes=10):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train_t.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "\n",
    "mlp_model = MLPClassifier(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m     11\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m, in \u001b[0;36mMLPClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1672\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marha\\.conda\\envs\\ai-environment\\lib\\site-packages\\torch\\nn\\functional.py:2140\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   2138\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in train_ds:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp_model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "393IbhMjBOg7"
   },
   "source": [
    "### Step 5: Experiment with different activation functions (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7Ndxo_oZBPu0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7614 - accuracy: 0.5672 - val_loss: 1.0969 - val_accuracy: 0.8139\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.8701 - val_loss: 0.4474 - val_accuracy: 0.8917\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.9198 - val_loss: 0.2845 - val_accuracy: 0.9222\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9399 - val_loss: 0.2167 - val_accuracy: 0.9444\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9562 - val_loss: 0.1896 - val_accuracy: 0.9417\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9577 - val_loss: 0.1603 - val_accuracy: 0.9417\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.9666 - val_loss: 0.1476 - val_accuracy: 0.9556\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9748 - val_loss: 0.1428 - val_accuracy: 0.9639\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9718 - val_loss: 0.1292 - val_accuracy: 0.9639\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9733 - val_loss: 0.1275 - val_accuracy: 0.9667\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9822 - val_loss: 0.1240 - val_accuracy: 0.9667\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9785 - val_loss: 0.1204 - val_accuracy: 0.9722\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9859 - val_loss: 0.1099 - val_accuracy: 0.9667\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9866 - val_loss: 0.1200 - val_accuracy: 0.9639\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9866 - val_loss: 0.1158 - val_accuracy: 0.9667\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9881 - val_loss: 0.1095 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9881 - val_loss: 0.1145 - val_accuracy: 0.9667\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9918 - val_loss: 0.1189 - val_accuracy: 0.9639\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9903 - val_loss: 0.1040 - val_accuracy: 0.9778\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9926 - val_loss: 0.1054 - val_accuracy: 0.9778\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9941 - val_loss: 0.1143 - val_accuracy: 0.9694\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9933 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9911 - val_loss: 0.1092 - val_accuracy: 0.9750\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9963 - val_loss: 0.1069 - val_accuracy: 0.9778\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 0.1116 - val_accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9926 - val_loss: 0.1060 - val_accuracy: 0.9778\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9963 - val_loss: 0.1041 - val_accuracy: 0.9722\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.1026 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9970 - val_loss: 0.1075 - val_accuracy: 0.9750\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9978 - val_loss: 0.1098 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='LeakyReLU', input_shape=(64,)),\n",
    "    keras.layers.Dense(64, activation='LeakyReLU'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.6891 - accuracy: 0.5761 - val_loss: 0.9995 - val_accuracy: 0.8361\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.8909 - val_loss: 0.4756 - val_accuracy: 0.9056\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.9302 - val_loss: 0.3102 - val_accuracy: 0.9333\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.9443 - val_loss: 0.2372 - val_accuracy: 0.9417\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9599 - val_loss: 0.1955 - val_accuracy: 0.9528\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9599 - val_loss: 0.1601 - val_accuracy: 0.9556\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9651 - val_loss: 0.1488 - val_accuracy: 0.9556\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9748 - val_loss: 0.1280 - val_accuracy: 0.9806\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9748 - val_loss: 0.1178 - val_accuracy: 0.9722\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9814 - val_loss: 0.1130 - val_accuracy: 0.9833\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9822 - val_loss: 0.1112 - val_accuracy: 0.9694\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9829 - val_loss: 0.1074 - val_accuracy: 0.9722\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9852 - val_loss: 0.1015 - val_accuracy: 0.9722\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9859 - val_loss: 0.1046 - val_accuracy: 0.9722\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9889 - val_loss: 0.1021 - val_accuracy: 0.9722\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9889 - val_loss: 0.0969 - val_accuracy: 0.9750\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9896 - val_loss: 0.0954 - val_accuracy: 0.9750\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9926 - val_loss: 0.0955 - val_accuracy: 0.9750\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9903 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9948 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9955 - val_loss: 0.0929 - val_accuracy: 0.9750\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9933 - val_loss: 0.0943 - val_accuracy: 0.9694\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9941 - val_loss: 0.0861 - val_accuracy: 0.9750\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9970 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9963 - val_loss: 0.0902 - val_accuracy: 0.9750\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9926 - val_loss: 0.0925 - val_accuracy: 0.9750\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9955 - val_loss: 0.0856 - val_accuracy: 0.9722\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9970 - val_loss: 0.0838 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9978 - val_loss: 0.0890 - val_accuracy: 0.9722\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.0883 - val_accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='tanh', input_shape=(64,)),\n",
    "    keras.layers.Dense(64, activation='tanh'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
