{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLP for Regression and Classificaiton using both PyTorch and Tensorflow"
      ],
      "metadata": {
        "id": "DFq2aBGJ3eZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Set Up the Environment\n",
        "Ensure you have PySpark, PyTorch, and other necessary libraries installed."
      ],
      "metadata": {
        "id": "4W0UFgQz3l9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "x2jK-moc3dMC"
      },
      "outputs": [],
      "source": [
        "# ! pip install pyspark torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers, Input\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "tiVmq72dUMG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: MLP for Regression – Predicting California Housing Prices\n",
        "\n"
      ],
      "metadata": {
        "id": "SeVRwwV04gSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Load and Prepare the Data\n",
        "* Load the California housing dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame for distributed processing.\n",
        "* Assemble feature vectors for PySpark."
      ],
      "metadata": {
        "id": "13jZ3NWm3iq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and Normalize California Housing Data\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing['target'] = housing.target  # Apply log transformation\n",
        "\n",
        "X = df_housing[housing.feature_names].values\n",
        "y = df_housing['target'].values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "oHTz8PN83vOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: [PyTorch] Convert Spark Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "lXoORM4A3wlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "_cGg8VbJ4z7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: [PyTorch] Build the MLP Model for Regression"
      ],
      "metadata": {
        "id": "hI-uZHPj48m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP architecture to match TensorFlow\n",
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPRegressor, self).__init__()\n",
        "        # First layer with BatchNorm\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Second layer with ReLU and then Dropout (matching TensorFlow placement)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)  # Moved dropout after ReLU to match TensorFlow\n",
        "        )\n",
        "        # Output layer\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "pt_model_regression = MLPRegressor(X_train.shape[1])\n",
        "\n",
        "# Use Adam optimizer with default settings to match TensorFlow\n",
        "# TensorFlow default Adam: lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7\n",
        "optimizer = optim.Adam(\n",
        "    pt_model_regression.parameters(),\n",
        "    lr=0.001,  # Default TensorFlow learning rate\n",
        "    betas=(0.9, 0.999),  # Default betas\n",
        "    eps=1e-8  # PyTorch default epsilon (slightly different from TF)\n",
        ")\n"
      ],
      "metadata": {
        "id": "0MPNiQx55D0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: [PyTorch] Train the Regression Model"
      ],
      "metadata": {
        "id": "w5l1N6rY5F6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Create DataLoader for mini-batch training\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Match TF batch size=32\n",
        "\n",
        "# Training loop with mini-batches (50 epochs to match TensorFlow)\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = pt_model_regression(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics (similar to TensorFlow verbose=1)\n",
        "    if epoch % 10 == 0 or epoch == num_epochs-1:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHJcyrO5Jk-",
        "outputId": "a2d5b940-9078-4c3d-8acf-0ceefad9412d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 1.1118\n",
            "Epoch [11/50], Loss: 0.4499\n",
            "Epoch [21/50], Loss: 0.4014\n",
            "Epoch [31/50], Loss: 0.3951\n",
            "Epoch [41/50], Loss: 0.3790\n",
            "Epoch [50/50], Loss: 0.3757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: [PyTorch] Evaluate the Regression Model"
      ],
      "metadata": {
        "id": "ASWz5pn_5LzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = pt_model_regression(X_test_t)\n",
        "    mse_loss = criterion(predictions, y_test_t)\n",
        "    mae_loss = nn.L1Loss()(predictions, y_test_t)  # Calculate MAE to match TensorFlow metrics\n",
        "\n",
        "print(f'Test Mean Squared Error: {mse_loss.item():.4f}')\n",
        "print(f'Test Mean Absolute Error: {mae_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2mKp1dp5lTZ",
        "outputId": "626193f7-594d-4fa5-ecce-d9837cdd7568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error: 0.3917\n",
            "Test Mean Absolute Error: 0.4252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: [PyTorch] Make Predictions with the Regression Model"
      ],
      "metadata": {
        "id": "z6b_D0Tf5oyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with scaled input (matching TensorFlow's approach)\n",
        "sample_input_np = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input_scaled = scaler.transform(sample_input_np)  # Apply scaling\n",
        "sample_input_t = torch.tensor(sample_input_scaled, dtype=torch.float32)\n",
        "\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    pt_prediction = pt_model_regression(sample_input_t).item()\n",
        "\n",
        "print(f'Predicted House Price: {pt_prediction:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBlDiRG5rlN",
        "outputId": "004aade6-5725-44f3-ff6d-537da37254c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted House Price: 3.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: [TensorFlow] Build the MLP Model for Regression"
      ],
      "metadata": {
        "id": "Izc9GcLd6_D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLP architecture\n",
        "tf_model_regression = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "tf_model_regression.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Display model summary\n",
        "tf_model_regression.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "-MmwmfrC7BXN",
        "outputId": "24e32411-035d-4da1-c8ec-5ad092cbe1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: [TensorFlow] Train the Regression Model"
      ],
      "metadata": {
        "id": "hBnx133N7IbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "tf_history_regression = tf_model_regression.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WSzTOKnx7OoX",
        "outputId": "4c9bf0a6-e7ec-4e28-f0dc-9d20b0b14cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 2.3640 - mae: 1.0957 - val_loss: 0.6972 - val_mae: 0.5605\n",
            "Epoch 2/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7154 - mae: 0.6240 - val_loss: 0.4585 - val_mae: 0.4613\n",
            "Epoch 3/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5867 - mae: 0.5569 - val_loss: 0.4454 - val_mae: 0.4504\n",
            "Epoch 4/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5274 - mae: 0.5249 - val_loss: 0.4404 - val_mae: 0.4668\n",
            "Epoch 5/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4906 - mae: 0.5030 - val_loss: 0.4563 - val_mae: 0.4750\n",
            "Epoch 6/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4586 - mae: 0.4821 - val_loss: 0.4040 - val_mae: 0.4459\n",
            "Epoch 7/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4648 - mae: 0.4829 - val_loss: 0.4038 - val_mae: 0.4457\n",
            "Epoch 8/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4193 - mae: 0.4617 - val_loss: 0.4333 - val_mae: 0.4621\n",
            "Epoch 9/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4145 - mae: 0.4512 - val_loss: 0.3838 - val_mae: 0.4395\n",
            "Epoch 10/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.4099 - mae: 0.4541 - val_loss: 0.3735 - val_mae: 0.4356\n",
            "Epoch 11/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3953 - mae: 0.4457 - val_loss: 0.3636 - val_mae: 0.4226\n",
            "Epoch 12/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3997 - mae: 0.4477 - val_loss: 0.3628 - val_mae: 0.4162\n",
            "Epoch 13/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3957 - mae: 0.4436 - val_loss: 0.3806 - val_mae: 0.4310\n",
            "Epoch 14/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3817 - mae: 0.4363 - val_loss: 0.3986 - val_mae: 0.4352\n",
            "Epoch 15/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3889 - mae: 0.4394 - val_loss: 0.3647 - val_mae: 0.4292\n",
            "Epoch 16/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3801 - mae: 0.4335 - val_loss: 0.3636 - val_mae: 0.4296\n",
            "Epoch 17/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3687 - mae: 0.4361 - val_loss: 0.3545 - val_mae: 0.4268\n",
            "Epoch 18/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3556 - mae: 0.4247 - val_loss: 0.3406 - val_mae: 0.4126\n",
            "Epoch 19/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3675 - mae: 0.4275 - val_loss: 0.3598 - val_mae: 0.4146\n",
            "Epoch 20/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3570 - mae: 0.4224 - val_loss: 0.3814 - val_mae: 0.4362\n",
            "Epoch 21/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3618 - mae: 0.4263 - val_loss: 0.3330 - val_mae: 0.3977\n",
            "Epoch 22/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3577 - mae: 0.4262 - val_loss: 0.3678 - val_mae: 0.4123\n",
            "Epoch 23/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3741 - mae: 0.4343 - val_loss: 0.3408 - val_mae: 0.4143\n",
            "Epoch 24/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3687 - mae: 0.4305 - val_loss: 0.3613 - val_mae: 0.4358\n",
            "Epoch 25/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3521 - mae: 0.4211 - val_loss: 0.3403 - val_mae: 0.4174\n",
            "Epoch 26/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3577 - mae: 0.4258 - val_loss: 0.3325 - val_mae: 0.4001\n",
            "Epoch 27/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3483 - mae: 0.4174 - val_loss: 0.3416 - val_mae: 0.4061\n",
            "Epoch 28/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3538 - mae: 0.4206 - val_loss: 0.3792 - val_mae: 0.4353\n",
            "Epoch 29/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3482 - mae: 0.4174 - val_loss: 0.3440 - val_mae: 0.4082\n",
            "Epoch 30/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3442 - mae: 0.4168 - val_loss: 0.3098 - val_mae: 0.3875\n",
            "Epoch 31/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3488 - mae: 0.4206 - val_loss: 0.3371 - val_mae: 0.4027\n",
            "Epoch 32/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3361 - mae: 0.4124 - val_loss: 0.3171 - val_mae: 0.3998\n",
            "Epoch 33/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3505 - mae: 0.4197 - val_loss: 0.3247 - val_mae: 0.3862\n",
            "Epoch 34/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3502 - mae: 0.4185 - val_loss: 0.3210 - val_mae: 0.4026\n",
            "Epoch 35/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3348 - mae: 0.4156 - val_loss: 0.3151 - val_mae: 0.3956\n",
            "Epoch 36/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3411 - mae: 0.4152 - val_loss: 0.3477 - val_mae: 0.4080\n",
            "Epoch 37/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3429 - mae: 0.4155 - val_loss: 0.3722 - val_mae: 0.4101\n",
            "Epoch 38/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3477 - mae: 0.4153 - val_loss: 0.3678 - val_mae: 0.4218\n",
            "Epoch 39/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3418 - mae: 0.4177 - val_loss: 0.3294 - val_mae: 0.4101\n",
            "Epoch 40/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3364 - mae: 0.4168 - val_loss: 0.3363 - val_mae: 0.3996\n",
            "Epoch 41/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3421 - mae: 0.4164 - val_loss: 0.3291 - val_mae: 0.4014\n",
            "Epoch 42/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3408 - mae: 0.4152 - val_loss: 0.3399 - val_mae: 0.4111\n",
            "Epoch 43/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3392 - mae: 0.4133 - val_loss: 0.3432 - val_mae: 0.4015\n",
            "Epoch 44/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3508 - mae: 0.4191 - val_loss: 0.3117 - val_mae: 0.3891\n",
            "Epoch 45/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3362 - mae: 0.4123 - val_loss: 0.3403 - val_mae: 0.4121\n",
            "Epoch 46/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3432 - mae: 0.4159 - val_loss: 0.3532 - val_mae: 0.4048\n",
            "Epoch 47/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3385 - mae: 0.4135 - val_loss: 0.3237 - val_mae: 0.4023\n",
            "Epoch 48/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3468 - mae: 0.4190 - val_loss: 0.3342 - val_mae: 0.4120\n",
            "Epoch 49/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3417 - mae: 0.4160 - val_loss: 0.3577 - val_mae: 0.4119\n",
            "Epoch 50/50\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3288 - mae: 0.4046 - val_loss: 0.3305 - val_mae: 0.3980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: [TensorFlow] Evaluate the Regression Model"
      ],
      "metadata": {
        "id": "OFOnyOGV7PU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss, mae = tf_model_regression.evaluate(X_test, y_test)\n",
        "print(f\"Test Mean Absolute Error: {mae:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaiR3tuf7S5h",
        "outputId": "a378a456-e250-44ff-a69e-c224db9bcaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3238 - mae: 0.4003\n",
            "Test Mean Absolute Error: 0.3980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10:[TensorFlow] Make Predictions with the Regression Model"
      ],
      "metadata": {
        "id": "puK16Lpi7Ua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input = scaler.transform(sample_input)  # Apply same scaling\n",
        "\n",
        "# Make prediction\n",
        "predicted_price = tf_model_regression.predict(sample_input)[0, 0]\n",
        "print(f\"Predicted House Price: {predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkiJibE7ae5",
        "outputId": "16252cc5-8c8d-4081-f948-1d8e8dfaf0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Predicted House Price: 3.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: MLP for Classification – Predicting Iris Flower Species"
      ],
      "metadata": {
        "id": "XGT_gcbwjO1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11: Load and Prepare the Data\n",
        "* Load the Iris dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame.\n",
        "* Encode categorical labels and assemble features."
      ],
      "metadata": {
        "id": "rpmSIlTOjPcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = iris.target\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = df_iris[iris.feature_names].values\n",
        "y = df_iris['label'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kvmpZTIdjWjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 12: (PyTorch) Convert Spark Data to PyTorch Tensors"
      ],
      "metadata": {
        "id": "Z99ffMINjYT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)  # Long tensor for classification\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "jlc8YIovje7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 13: (PyTorch) Build the MLP Model for Classification"
      ],
      "metadata": {
        "id": "Ydzx9We9jhl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 16\n",
        "output_size = len(iris.target_names)\n",
        "\n",
        "pt_model_classification = MLPClassifier(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(pt_model_classification.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HX-39tkXjj1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 14: (PyTorch) Train the Classification Model"
      ],
      "metadata": {
        "id": "Z_G4WcvJjl57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = pt_model_classification(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNI2uYtjnnt",
        "outputId": "3ac14a70-2dcb-411f-b55d-994084dea9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], Loss: 1.1314\n",
            "Epoch [10/100], Loss: 0.9563\n",
            "Epoch [20/100], Loss: 0.8416\n",
            "Epoch [30/100], Loss: 0.7718\n",
            "Epoch [40/100], Loss: 0.7206\n",
            "Epoch [50/100], Loss: 0.6832\n",
            "Epoch [60/100], Loss: 0.6491\n",
            "Epoch [70/100], Loss: 0.6195\n",
            "Epoch [80/100], Loss: 0.6032\n",
            "Epoch [90/100], Loss: 0.5942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 15: (PyTorch) Evaluate the Classification Model"
      ],
      "metadata": {
        "id": "BF9t_-Ykjt7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions = pt_model_classification(X_test_t)\n",
        "    predicted_labels = torch.argmax(predictions, axis=1)\n",
        "    accuracy = (predicted_labels == y_test_t).sum().item() / y_test_t.size(0)\n",
        "\n",
        "print(f'Classification Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRkJ9flj3DS",
        "outputId": "872af9f5-83f7-4e7c-95e7-9f3126ad2f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 16: (PyTorch) Make Predictions with the Classification Model"
      ],
      "metadata": {
        "id": "GY0yhjstj60B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.tensor([[6.7, 3.1, 4.9, 1.5]])  # Example from dataset\n",
        "with torch.no_grad():\n",
        "    prediction = pt_model_classification(sample_input)\n",
        "    predicted_class = torch.argmax(prediction, axis=1).item()\n",
        "\n",
        "print(f'Predicted Class: {iris.target_names[predicted_class]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At8UV4Zfj_z8",
        "outputId": "ebcc0099-5bec-462a-b62c-37868a79dbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 17: (TensorFlow) Build the MLP Model for Classification"
      ],
      "metadata": {
        "id": "8QSJHKRJkDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Create a new model (to avoid sharing weights)\n",
        "tf_model_classification = keras.Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Define input layer\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile with categorical crossentropy\n",
        "tf_model_classification.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "tf_model_classification.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ImEuEZdlkHPM",
        "outputId": "3bc9877b-8641-4d42-f8c5-10f71aad3f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m243\u001b[0m (972.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243</span> (972.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 18: (TensorFlow) Train the Classification Model"
      ],
      "metadata": {
        "id": "TZnTxlzfkJsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_classification = tf_model_classification.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqY1KIDkQqR",
        "outputId": "70842006-61fd-4d7a-9375-374b4043a405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6147 - loss: 1.0142 - val_accuracy: 0.5000 - val_loss: 0.9920\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6684 - loss: 0.9703 - val_accuracy: 0.5667 - val_loss: 0.9403\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 0.9166 - val_accuracy: 0.7333 - val_loss: 0.8911\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6148 - loss: 0.8972 - val_accuracy: 0.7333 - val_loss: 0.8447\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 0.8276 - val_accuracy: 0.7333 - val_loss: 0.7992\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6937 - loss: 0.7670 - val_accuracy: 0.7333 - val_loss: 0.7581\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6613 - loss: 0.7939 - val_accuracy: 0.7333 - val_loss: 0.7190\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7379 - loss: 0.7330 - val_accuracy: 0.7333 - val_loss: 0.6814\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7220 - loss: 0.6800 - val_accuracy: 0.7333 - val_loss: 0.6460\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7330 - loss: 0.6577 - val_accuracy: 0.7333 - val_loss: 0.6142\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7137 - loss: 0.6368 - val_accuracy: 0.7333 - val_loss: 0.5853\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6571 - loss: 0.6518 - val_accuracy: 0.7333 - val_loss: 0.5598\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6599 - loss: 0.6353 - val_accuracy: 0.7333 - val_loss: 0.5370\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7454 - loss: 0.5452 - val_accuracy: 0.7333 - val_loss: 0.5167\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7048 - loss: 0.5997 - val_accuracy: 0.7667 - val_loss: 0.4992\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7290 - loss: 0.5690 - val_accuracy: 0.8000 - val_loss: 0.4823\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7613 - loss: 0.5148 - val_accuracy: 0.8000 - val_loss: 0.4671\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8151 - loss: 0.4913 - val_accuracy: 0.8000 - val_loss: 0.4530\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8202 - loss: 0.4798 - val_accuracy: 0.8000 - val_loss: 0.4400\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8038 - loss: 0.4860 - val_accuracy: 0.8000 - val_loss: 0.4276\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7951 - loss: 0.4855 - val_accuracy: 0.8333 - val_loss: 0.4160\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8383 - loss: 0.4443 - val_accuracy: 0.8333 - val_loss: 0.4055\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.4683 - val_accuracy: 0.8333 - val_loss: 0.3948\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.4607 - val_accuracy: 0.8667 - val_loss: 0.3849\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8242 - loss: 0.4707 - val_accuracy: 0.8667 - val_loss: 0.3747\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.4303 - val_accuracy: 0.8667 - val_loss: 0.3652\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8499 - loss: 0.3722 - val_accuracy: 0.9000 - val_loss: 0.3562\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8403 - loss: 0.4152 - val_accuracy: 0.9000 - val_loss: 0.3470\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8158 - loss: 0.3986 - val_accuracy: 0.9000 - val_loss: 0.3384\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8453 - loss: 0.3960 - val_accuracy: 0.9000 - val_loss: 0.3290\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8534 - loss: 0.3898 - val_accuracy: 0.9000 - val_loss: 0.3195\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8325 - loss: 0.4080 - val_accuracy: 0.9000 - val_loss: 0.3105\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8470 - loss: 0.3880 - val_accuracy: 0.9000 - val_loss: 0.3015\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8648 - loss: 0.3525 - val_accuracy: 0.9000 - val_loss: 0.2933\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.3155 - val_accuracy: 0.9000 - val_loss: 0.2847\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8419 - loss: 0.3579 - val_accuracy: 0.9333 - val_loss: 0.2770\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8937 - loss: 0.3310 - val_accuracy: 0.9333 - val_loss: 0.2687\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.2849 - val_accuracy: 0.9667 - val_loss: 0.2604\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9232 - loss: 0.3082 - val_accuracy: 0.9667 - val_loss: 0.2523\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8683 - loss: 0.3392 - val_accuracy: 0.9667 - val_loss: 0.2444\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8963 - loss: 0.2889 - val_accuracy: 0.9667 - val_loss: 0.2370\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9056 - loss: 0.3103 - val_accuracy: 0.9667 - val_loss: 0.2292\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9222 - loss: 0.2958 - val_accuracy: 0.9667 - val_loss: 0.2219\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9197 - loss: 0.2721 - val_accuracy: 0.9667 - val_loss: 0.2147\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9244 - loss: 0.2781 - val_accuracy: 0.9667 - val_loss: 0.2076\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.2174 - val_accuracy: 0.9667 - val_loss: 0.2021\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9150 - loss: 0.2583 - val_accuracy: 0.9667 - val_loss: 0.1957\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9115 - loss: 0.2606 - val_accuracy: 0.9667 - val_loss: 0.1892\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9235 - loss: 0.2266 - val_accuracy: 0.9667 - val_loss: 0.1828\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.2370 - val_accuracy: 0.9667 - val_loss: 0.1771\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.2069 - val_accuracy: 0.9667 - val_loss: 0.1736\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9027 - loss: 0.2465 - val_accuracy: 0.9667 - val_loss: 0.1679\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.2574 - val_accuracy: 0.9667 - val_loss: 0.1638\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.2030 - val_accuracy: 0.9667 - val_loss: 0.1588\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.2239 - val_accuracy: 0.9667 - val_loss: 0.1539\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9366 - loss: 0.1921 - val_accuracy: 0.9667 - val_loss: 0.1508\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.1868 - val_accuracy: 0.9667 - val_loss: 0.1461\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9406 - loss: 0.2083 - val_accuracy: 0.9667 - val_loss: 0.1400\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.1964 - val_accuracy: 0.9667 - val_loss: 0.1375\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9537 - loss: 0.1829 - val_accuracy: 0.9667 - val_loss: 0.1341\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.1708 - val_accuracy: 0.9667 - val_loss: 0.1298\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.1831 - val_accuracy: 0.9667 - val_loss: 0.1267\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9529 - loss: 0.1548 - val_accuracy: 0.9667 - val_loss: 0.1241\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9700 - loss: 0.1759 - val_accuracy: 0.9667 - val_loss: 0.1202\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9392 - loss: 0.1682 - val_accuracy: 1.0000 - val_loss: 0.1173\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.1695 - val_accuracy: 1.0000 - val_loss: 0.1141\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9611 - loss: 0.1294 - val_accuracy: 1.0000 - val_loss: 0.1111\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1411 - val_accuracy: 1.0000 - val_loss: 0.1094\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9489 - loss: 0.1620 - val_accuracy: 1.0000 - val_loss: 0.1076\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.1585 - val_accuracy: 1.0000 - val_loss: 0.1046\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9562 - loss: 0.1387 - val_accuracy: 1.0000 - val_loss: 0.1035\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1592 - val_accuracy: 1.0000 - val_loss: 0.1014\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.1375 - val_accuracy: 1.0000 - val_loss: 0.0999\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9619 - loss: 0.1431 - val_accuracy: 1.0000 - val_loss: 0.0971\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9584 - loss: 0.1584 - val_accuracy: 1.0000 - val_loss: 0.0967\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.1106 - val_accuracy: 1.0000 - val_loss: 0.0934\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1510 - val_accuracy: 1.0000 - val_loss: 0.0899\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.1242 - val_accuracy: 1.0000 - val_loss: 0.0895\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.1291 - val_accuracy: 1.0000 - val_loss: 0.0878\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.0868\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.1339 - val_accuracy: 1.0000 - val_loss: 0.0847\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0928 - val_accuracy: 1.0000 - val_loss: 0.0819\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.1086 - val_accuracy: 1.0000 - val_loss: 0.0807\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.1036 - val_accuracy: 1.0000 - val_loss: 0.0809\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.0967 - val_accuracy: 1.0000 - val_loss: 0.0777\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9736 - loss: 0.1237 - val_accuracy: 1.0000 - val_loss: 0.0766\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9826 - loss: 0.0953 - val_accuracy: 1.0000 - val_loss: 0.0758\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.1185 - val_accuracy: 1.0000 - val_loss: 0.0741\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9712 - loss: 0.1021 - val_accuracy: 1.0000 - val_loss: 0.0724\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0754 - val_accuracy: 1.0000 - val_loss: 0.0710\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.1141 - val_accuracy: 1.0000 - val_loss: 0.0704\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9802 - loss: 0.0903 - val_accuracy: 1.0000 - val_loss: 0.0699\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9648 - loss: 0.1044 - val_accuracy: 1.0000 - val_loss: 0.0696\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9677 - loss: 0.0966 - val_accuracy: 1.0000 - val_loss: 0.0681\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9749 - loss: 0.0855 - val_accuracy: 1.0000 - val_loss: 0.0670\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0869 - val_accuracy: 1.0000 - val_loss: 0.0649\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.0978 - val_accuracy: 1.0000 - val_loss: 0.0647\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.1103 - val_accuracy: 1.0000 - val_loss: 0.0635\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9578 - loss: 0.0900 - val_accuracy: 1.0000 - val_loss: 0.0627\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9582 - loss: 0.0936 - val_accuracy: 1.0000 - val_loss: 0.0617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 19: (TensorFlow) Evaluate the Classification Model"
      ],
      "metadata": {
        "id": "55bD72DDkTZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "# Use one-hot encoded labels for evaluation\n",
        "loss, accuracy = tf_model_classification.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gq3bLY5kZJ-",
        "outputId": "cdef52fe-faca-4392-9605-03c15805d893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0617\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 20: Make Predictions with the Classification Model"
      ],
      "metadata": {
        "id": "3LtG1TMOkbye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[6.7, 3.1, 4.9, 1.5]])  # Example from Iris dataset\n",
        "\n",
        "# Make prediction\n",
        "tf_model_classification_prediction = tf_model_classification.predict(sample_input)\n",
        "tf_predicted_class = np.argmax(tf_model_classification_prediction, axis=1)[0]\n",
        "\n",
        "# Output predicted class\n",
        "print(f\"Predicted Class: {iris.target_names[predicted_class]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xw_4XskcJS",
        "outputId": "665c9d83-fe73-4d66-9ecb-0b932a28ef60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Predicted Class: virginica\n"
          ]
        }
      ]
    }
  ]
}