{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFq2aBGJ3eZg"
      },
      "source": [
        "# MLP for Regression and Classificaiton using both PyTorch and Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W0UFgQz3l9K"
      },
      "source": [
        "### Step 0: Set Up the Environment\n",
        "Ensure you have PySpark, PyTorch, and other necessary libraries installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "x2jK-moc3dMC"
      },
      "outputs": [],
      "source": [
        "# ! pip install pyspark torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tiVmq72dUMG-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from keras import layers, Input\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeVRwwV04gSP"
      },
      "source": [
        "## Part 1: MLP for Regression – Predicting California Housing Prices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13jZ3NWm3iq9"
      },
      "source": [
        "### Step 1: Load and Prepare the Data\n",
        "* Load the California housing dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame for distributed processing.\n",
        "* Assemble feature vectors for PySpark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oHTz8PN83vOi"
      },
      "outputs": [],
      "source": [
        "# Load and Normalize California Housing Data\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing['target'] = housing.target  # Apply log transformation\n",
        "\n",
        "X = df_housing[housing.feature_names].values\n",
        "y = df_housing['target'].values\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXoORM4A3wlC"
      },
      "source": [
        "### Step 2: [PyTorch] Convert Spark Data to PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_cGg8VbJ4z7H"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI-uZHPj48m6"
      },
      "source": [
        "### Step 3: [PyTorch] Build the MLP Model for Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0MPNiQx55D0U"
      },
      "outputs": [],
      "source": [
        "# Define MLP architecture to match TensorFlow\n",
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPRegressor, self).__init__()\n",
        "        # First layer with BatchNorm\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Second layer with ReLU and then Dropout (matching TensorFlow placement)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3)  # Moved dropout after ReLU to match TensorFlow\n",
        "        )\n",
        "        # Output layer\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "pt_model_regression = MLPRegressor(X_train.shape[1])\n",
        "\n",
        "# Use Adam optimizer with default settings to match TensorFlow\n",
        "# TensorFlow default Adam: lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7\n",
        "optimizer = optim.Adam(\n",
        "    pt_model_regression.parameters(),\n",
        "    lr=0.001,  # Default TensorFlow learning rate\n",
        "    betas=(0.9, 0.999),  # Default betas\n",
        "    eps=1e-8  # PyTorch default epsilon (slightly different from TF)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5l1N6rY5F6g"
      },
      "source": [
        "### Step 4: [PyTorch] Train the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkHJcyrO5Jk-",
        "outputId": "a2d5b940-9078-4c3d-8acf-0ceefad9412d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 1.0573\n",
            "Epoch [11/50], Loss: 0.4339\n",
            "Epoch [21/50], Loss: 0.3940\n",
            "Epoch [31/50], Loss: 0.3899\n",
            "Epoch [41/50], Loss: 0.3662\n",
            "Epoch [50/50], Loss: 0.3666\n"
          ]
        }
      ],
      "source": [
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Create DataLoader for mini-batch training\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Match TF batch size=32\n",
        "\n",
        "# Training loop with mini-batches (50 epochs to match TensorFlow)\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Mini-batch training\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = pt_model_regression(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics (similar to TensorFlow verbose=1)\n",
        "    if epoch % 10 == 0 or epoch == num_epochs-1:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASWz5pn_5LzS"
      },
      "source": [
        "### Step 5: [PyTorch] Evaluate the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2mKp1dp5lTZ",
        "outputId": "626193f7-594d-4fa5-ecce-d9837cdd7568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Mean Squared Error: 0.3132\n",
            "Test Mean Absolute Error: 0.3843\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = pt_model_regression(X_test_t)\n",
        "    mse_loss = criterion(predictions, y_test_t)\n",
        "    mae_loss = nn.L1Loss()(predictions, y_test_t)  # Calculate MAE to match TensorFlow metrics\n",
        "\n",
        "print(f'Test Mean Squared Error: {mse_loss.item():.4f}')\n",
        "print(f'Test Mean Absolute Error: {mae_loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6b_D0Tf5oyv"
      },
      "source": [
        "### Step 6: [PyTorch] Make Predictions with the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZBlDiRG5rlN",
        "outputId": "004aade6-5725-44f3-ff6d-537da37254c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted House Price: 3.64\n"
          ]
        }
      ],
      "source": [
        "# Make predictions with scaled input (matching TensorFlow's approach)\n",
        "sample_input_np = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input_scaled = scaler.transform(sample_input_np)  # Apply scaling\n",
        "sample_input_t = torch.tensor(sample_input_scaled, dtype=torch.float32)\n",
        "\n",
        "pt_model_regression.eval()\n",
        "with torch.no_grad():\n",
        "    pt_prediction = pt_model_regression(sample_input_t).item()\n",
        "\n",
        "print(f'Predicted House Price: {pt_prediction:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izc9GcLd6_D-"
      },
      "source": [
        "### Step 7: [TensorFlow] Build the MLP Model for Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "-MmwmfrC7BXN",
        "outputId": "24e32411-035d-4da1-c8ec-5ad092cbe1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,945\n",
            "Trainable params: 2,817\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define MLP architecture\n",
        "tf_model_regression = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "tf_model_regression.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Display model summary\n",
        "tf_model_regression.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBnx133N7IbV"
      },
      "source": [
        "### Step 8: [TensorFlow] Train the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WSzTOKnx7OoX",
        "outputId": "4c9bf0a6-e7ec-4e28-f0dc-9d20b0b14cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 1.2784 - mae: 0.8239 - val_loss: 0.6203 - val_mae: 0.5431\n",
            "Epoch 2/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.6955 - mae: 0.6124 - val_loss: 0.5073 - val_mae: 0.4976\n",
            "Epoch 3/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.5741 - mae: 0.5503 - val_loss: 0.4650 - val_mae: 0.4789\n",
            "Epoch 4/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.5298 - mae: 0.5248 - val_loss: 0.3989 - val_mae: 0.4335\n",
            "Epoch 5/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4889 - mae: 0.5033 - val_loss: 0.4236 - val_mae: 0.4542\n",
            "Epoch 6/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4727 - mae: 0.4910 - val_loss: 0.3822 - val_mae: 0.4259\n",
            "Epoch 7/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4584 - mae: 0.4838 - val_loss: 0.4007 - val_mae: 0.4599\n",
            "Epoch 8/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4390 - mae: 0.4725 - val_loss: 0.3618 - val_mae: 0.4251\n",
            "Epoch 9/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4239 - mae: 0.4632 - val_loss: 0.3957 - val_mae: 0.4450\n",
            "Epoch 10/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4167 - mae: 0.4614 - val_loss: 0.3667 - val_mae: 0.4334\n",
            "Epoch 11/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4174 - mae: 0.4589 - val_loss: 0.3953 - val_mae: 0.4521\n",
            "Epoch 12/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4096 - mae: 0.4553 - val_loss: 0.3581 - val_mae: 0.4275\n",
            "Epoch 13/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4071 - mae: 0.4546 - val_loss: 0.3886 - val_mae: 0.4470\n",
            "Epoch 14/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3983 - mae: 0.4472 - val_loss: 0.3783 - val_mae: 0.4321\n",
            "Epoch 15/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3867 - mae: 0.4407 - val_loss: 0.3285 - val_mae: 0.4021\n",
            "Epoch 16/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3894 - mae: 0.4421 - val_loss: 0.4002 - val_mae: 0.4708\n",
            "Epoch 17/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3759 - mae: 0.4358 - val_loss: 0.3464 - val_mae: 0.4198\n",
            "Epoch 18/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3918 - mae: 0.4442 - val_loss: 0.3528 - val_mae: 0.4206\n",
            "Epoch 19/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3759 - mae: 0.4354 - val_loss: 0.3455 - val_mae: 0.4242\n",
            "Epoch 20/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3750 - mae: 0.4374 - val_loss: 0.3438 - val_mae: 0.4161\n",
            "Epoch 21/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3760 - mae: 0.4365 - val_loss: 0.3516 - val_mae: 0.4279\n",
            "Epoch 22/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3707 - mae: 0.4330 - val_loss: 0.3329 - val_mae: 0.4066\n",
            "Epoch 23/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3619 - mae: 0.4273 - val_loss: 0.3459 - val_mae: 0.4245\n",
            "Epoch 24/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3613 - mae: 0.4269 - val_loss: 0.3160 - val_mae: 0.3912\n",
            "Epoch 25/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3627 - mae: 0.4284 - val_loss: 0.3423 - val_mae: 0.4189\n",
            "Epoch 26/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3622 - mae: 0.4289 - val_loss: 0.3641 - val_mae: 0.4307\n",
            "Epoch 27/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3573 - mae: 0.4263 - val_loss: 0.3720 - val_mae: 0.4429\n",
            "Epoch 28/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3592 - mae: 0.4288 - val_loss: 0.3501 - val_mae: 0.4115\n",
            "Epoch 29/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3539 - mae: 0.4226 - val_loss: 0.3701 - val_mae: 0.4435\n",
            "Epoch 30/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3644 - mae: 0.4307 - val_loss: 0.3398 - val_mae: 0.4161\n",
            "Epoch 31/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3583 - mae: 0.4268 - val_loss: 0.3543 - val_mae: 0.4335\n",
            "Epoch 32/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3455 - mae: 0.4201 - val_loss: 0.3511 - val_mae: 0.4139\n",
            "Epoch 33/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3546 - mae: 0.4249 - val_loss: 0.3560 - val_mae: 0.4349\n",
            "Epoch 34/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3497 - mae: 0.4227 - val_loss: 0.3095 - val_mae: 0.3895\n",
            "Epoch 35/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3469 - mae: 0.4193 - val_loss: 0.3570 - val_mae: 0.4393\n",
            "Epoch 36/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3506 - mae: 0.4201 - val_loss: 0.3726 - val_mae: 0.4448\n",
            "Epoch 37/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3492 - mae: 0.4210 - val_loss: 0.3269 - val_mae: 0.4159\n",
            "Epoch 38/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3466 - mae: 0.4216 - val_loss: 0.3035 - val_mae: 0.3810\n",
            "Epoch 39/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3454 - mae: 0.4192 - val_loss: 0.3201 - val_mae: 0.3937\n",
            "Epoch 40/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3490 - mae: 0.4217 - val_loss: 0.3412 - val_mae: 0.4126\n",
            "Epoch 41/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3488 - mae: 0.4221 - val_loss: 0.3247 - val_mae: 0.3931\n",
            "Epoch 42/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3463 - mae: 0.4208 - val_loss: 0.3049 - val_mae: 0.3822\n",
            "Epoch 43/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3416 - mae: 0.4158 - val_loss: 0.3361 - val_mae: 0.4176\n",
            "Epoch 44/50\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.3402 - mae: 0.4169 - val_loss: 0.3323 - val_mae: 0.4130\n",
            "Epoch 45/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3417 - mae: 0.4169 - val_loss: 0.3396 - val_mae: 0.4001\n",
            "Epoch 46/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3462 - mae: 0.4215 - val_loss: 0.3356 - val_mae: 0.4187\n",
            "Epoch 47/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3437 - mae: 0.4191 - val_loss: 0.3084 - val_mae: 0.3855\n",
            "Epoch 48/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3414 - mae: 0.4185 - val_loss: 0.3276 - val_mae: 0.4205\n",
            "Epoch 49/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3419 - mae: 0.4172 - val_loss: 0.3531 - val_mae: 0.4357\n",
            "Epoch 50/50\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3427 - mae: 0.4192 - val_loss: 0.3167 - val_mae: 0.3896\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "tf_history_regression = tf_model_regression.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOnyOGV7PU7"
      },
      "source": [
        "### Step 9: [TensorFlow] Evaluate the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaiR3tuf7S5h",
        "outputId": "a378a456-e250-44ff-a69e-c224db9bcaf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "129/129 [==============================] - 0s 1ms/step - loss: 0.3167 - mae: 0.3896\n",
            "Test Mean Absolute Error: 0.3896\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "loss, mae = tf_model_regression.evaluate(X_test, y_test)\n",
        "print(f\"Test Mean Absolute Error: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puK16Lpi7Ua8"
      },
      "source": [
        "### Step 10:[TensorFlow] Make Predictions with the Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkiJibE7ae5",
        "outputId": "16252cc5-8c8d-4081-f948-1d8e8dfaf0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n",
            "Predicted House Price: 2.79\n"
          ]
        }
      ],
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[8.0, 41.0, 6.0, 1.0, 950.0, 4.0, 37.0, -122.0]])\n",
        "sample_input = scaler.transform(sample_input)  # Apply same scaling\n",
        "\n",
        "# Make prediction\n",
        "predicted_price = tf_model_regression.predict(sample_input)[0, 0]\n",
        "print(f\"Predicted House Price: {predicted_price:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGT_gcbwjO1p"
      },
      "source": [
        "## Part 2: MLP for Classification – Predicting Iris Flower Species"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpmSIlTOjPcg"
      },
      "source": [
        "### Step 11: Load and Prepare the Data\n",
        "* Load the Iris dataset into a Pandas DataFrame.\n",
        "* Convert it into a Spark DataFrame.\n",
        "* Encode categorical labels and assemble features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kvmpZTIdjWjZ"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = iris.target\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = df_iris[iris.feature_names].values\n",
        "y = df_iris['label'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z99ffMINjYT5"
      },
      "source": [
        "### Step 12: (PyTorch) Convert Spark Data to PyTorch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jlc8YIovje7d"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)  # Long tensor for classification\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydzx9We9jhl2"
      },
      "source": [
        "### Step 13: (PyTorch) Build the MLP Model for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HX-39tkXjj1_"
      },
      "outputs": [],
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_t.shape[1]\n",
        "hidden_size = 16\n",
        "output_size = len(iris.target_names)\n",
        "\n",
        "pt_model_classification = MLPClassifier(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(pt_model_classification.parameters(), lr=0.01)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_G4WcvJjl57"
      },
      "source": [
        "### Step 14: (PyTorch) Train the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrNI2uYtjnnt",
        "outputId": "3ac14a70-2dcb-411f-b55d-994084dea9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/100], Loss: 1.0494\n",
            "Epoch [10/100], Loss: 0.8573\n",
            "Epoch [20/100], Loss: 0.7799\n",
            "Epoch [30/100], Loss: 0.7298\n",
            "Epoch [40/100], Loss: 0.6963\n",
            "Epoch [50/100], Loss: 0.6646\n",
            "Epoch [60/100], Loss: 0.6334\n",
            "Epoch [70/100], Loss: 0.6131\n",
            "Epoch [80/100], Loss: 0.6010\n",
            "Epoch [90/100], Loss: 0.5941\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = pt_model_classification(X_train_t)\n",
        "    loss = criterion(outputs, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF9t_-Ykjt7s"
      },
      "source": [
        "### Step 15: (PyTorch) Evaluate the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRkJ9flj3DS",
        "outputId": "872af9f5-83f7-4e7c-95e7-9f3126ad2f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    predictions = pt_model_classification(X_test_t)\n",
        "    predicted_labels = torch.argmax(predictions, axis=1)\n",
        "    accuracy = (predicted_labels == y_test_t).sum().item() / y_test_t.size(0)\n",
        "\n",
        "print(f'Classification Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY0yhjstj60B"
      },
      "source": [
        "### Step 16: (PyTorch) Make Predictions with the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At8UV4Zfj_z8",
        "outputId": "ebcc0099-5bec-462a-b62c-37868a79dbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: virginica\n"
          ]
        }
      ],
      "source": [
        "sample_input = torch.tensor([[6.7, 3.1, 4.9, 1.5]])  # Example from dataset\n",
        "with torch.no_grad():\n",
        "    prediction = pt_model_classification(sample_input)\n",
        "    predicted_class = torch.argmax(prediction, axis=1).item()\n",
        "\n",
        "print(f'Predicted Class: {iris.target_names[predicted_class]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QSJHKRJkDGf"
      },
      "source": [
        "### Step 17: (TensorFlow) Build the MLP Model for Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ImEuEZdlkHPM",
        "outputId": "3bc9877b-8641-4d42-f8c5-10f71aad3f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243\n",
            "Trainable params: 243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Create a new model (to avoid sharing weights)\n",
        "tf_model_classification = keras.Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Define input layer\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile with categorical crossentropy\n",
        "tf_model_classification.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "tf_model_classification.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZnTxlzfkJsf"
      },
      "source": [
        "### Step 18: (TensorFlow) Train the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqY1KIDkQqR",
        "outputId": "70842006-61fd-4d7a-9375-374b4043a405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0623 - accuracy: 0.3583 - val_loss: 1.0300 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0224 - accuracy: 0.3750 - val_loss: 0.9918 - val_accuracy: 0.4667\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9828 - accuracy: 0.4083 - val_loss: 0.9567 - val_accuracy: 0.4667\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9454 - accuracy: 0.4250 - val_loss: 0.9235 - val_accuracy: 0.5333\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9142 - accuracy: 0.4500 - val_loss: 0.8914 - val_accuracy: 0.5667\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8830 - accuracy: 0.4583 - val_loss: 0.8641 - val_accuracy: 0.5667\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.4750 - val_loss: 0.8391 - val_accuracy: 0.5667\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8342 - accuracy: 0.5083 - val_loss: 0.8163 - val_accuracy: 0.6333\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8132 - accuracy: 0.5167 - val_loss: 0.7964 - val_accuracy: 0.7333\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7952 - accuracy: 0.5750 - val_loss: 0.7784 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.6167 - val_loss: 0.7620 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.6750 - val_loss: 0.7472 - val_accuracy: 0.8667\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.7000 - val_loss: 0.7339 - val_accuracy: 0.8667\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.7250 - val_loss: 0.7206 - val_accuracy: 0.9000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.7333 - val_loss: 0.7074 - val_accuracy: 0.9000\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.7583 - val_loss: 0.6951 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.8000 - val_loss: 0.6824 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.7833 - val_loss: 0.6695 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.7833 - val_loss: 0.6564 - val_accuracy: 0.8333\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.7917 - val_loss: 0.6429 - val_accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7833 - val_loss: 0.6290 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.7750 - val_loss: 0.6147 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.7917 - val_loss: 0.6001 - val_accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7833 - val_loss: 0.5848 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6016 - accuracy: 0.7833 - val_loss: 0.5703 - val_accuracy: 0.7667\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7917 - val_loss: 0.5560 - val_accuracy: 0.7667\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7833 - val_loss: 0.5405 - val_accuracy: 0.7667\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7917 - val_loss: 0.5261 - val_accuracy: 0.7667\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7917 - val_loss: 0.5110 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8083 - val_loss: 0.4954 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8167 - val_loss: 0.4802 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.8167 - val_loss: 0.4648 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.8167 - val_loss: 0.4505 - val_accuracy: 0.8333\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.8167 - val_loss: 0.4357 - val_accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.8167 - val_loss: 0.4229 - val_accuracy: 0.8333\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.8167 - val_loss: 0.4100 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.8167 - val_loss: 0.3981 - val_accuracy: 0.8667\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8167 - val_loss: 0.3871 - val_accuracy: 0.8667\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8250 - val_loss: 0.3765 - val_accuracy: 0.8667\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8333 - val_loss: 0.3658 - val_accuracy: 0.8667\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8417 - val_loss: 0.3555 - val_accuracy: 0.8667\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8417 - val_loss: 0.3457 - val_accuracy: 0.8667\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8417 - val_loss: 0.3367 - val_accuracy: 0.8667\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8417 - val_loss: 0.3273 - val_accuracy: 0.9000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3696 - accuracy: 0.8417 - val_loss: 0.3184 - val_accuracy: 0.9000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8333 - val_loss: 0.3092 - val_accuracy: 0.9000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8333 - val_loss: 0.3000 - val_accuracy: 0.9000\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8333 - val_loss: 0.2909 - val_accuracy: 0.9000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8333 - val_loss: 0.2832 - val_accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8417 - val_loss: 0.2749 - val_accuracy: 0.9000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8583 - val_loss: 0.2665 - val_accuracy: 0.9000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8667 - val_loss: 0.2582 - val_accuracy: 0.9000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8833 - val_loss: 0.2496 - val_accuracy: 0.9000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.8917 - val_loss: 0.2427 - val_accuracy: 0.9000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8917 - val_loss: 0.2348 - val_accuracy: 0.9333\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9000 - val_loss: 0.2275 - val_accuracy: 0.9333\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9083 - val_loss: 0.2204 - val_accuracy: 0.9333\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2654 - accuracy: 0.9250 - val_loss: 0.2133 - val_accuracy: 0.9333\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.9250 - val_loss: 0.2072 - val_accuracy: 0.9333\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2515 - accuracy: 0.9250 - val_loss: 0.2016 - val_accuracy: 0.9667\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9250 - val_loss: 0.1954 - val_accuracy: 0.9667\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9250 - val_loss: 0.1908 - val_accuracy: 0.9667\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2322 - accuracy: 0.9333 - val_loss: 0.1849 - val_accuracy: 0.9667\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2259 - accuracy: 0.9333 - val_loss: 0.1792 - val_accuracy: 0.9667\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9250 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9417 - val_loss: 0.1685 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9417 - val_loss: 0.1647 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9417 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9333 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9333 - val_loss: 0.1547 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9333 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9333 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.9333 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.9500 - val_loss: 0.1390 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9417 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9417 - val_loss: 0.1341 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.9500 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9583 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9500 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9500 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1521 - accuracy: 0.9500 - val_loss: 0.1226 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9500 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9500 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9500 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9500 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9500 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9583 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9583 - val_loss: 0.1093 - val_accuracy: 0.9667\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9583 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9583 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9583 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9583 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9500 - val_loss: 0.0990 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9500 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9583 - val_loss: 0.0963 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9583 - val_loss: 0.0943 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9583 - val_loss: 0.0943 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9583 - val_loss: 0.0920 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history_classification = tf_model_classification.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55bD72DDkTZF"
      },
      "source": [
        "### Step 19: (TensorFlow) Evaluate the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gq3bLY5kZJ-",
        "outputId": "cdef52fe-faca-4392-9605-03c15805d893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0920 - accuracy: 1.0000\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "# Use one-hot encoded labels for evaluation\n",
        "loss, accuracy = tf_model_classification.evaluate(X_test, y_test_one_hot)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LtG1TMOkbye"
      },
      "source": [
        "### Step 20: Make Predictions with the Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xw_4XskcJS",
        "outputId": "665c9d83-fe73-4d66-9ecb-0b932a28ef60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Predicted Class: virginica\n"
          ]
        }
      ],
      "source": [
        "# Sample input for prediction\n",
        "sample_input = np.array([[6.7, 3.1, 4.9, 1.5]])  # Example from Iris dataset\n",
        "\n",
        "# Make prediction\n",
        "tf_model_classification_prediction = tf_model_classification.predict(sample_input)\n",
        "tf_predicted_class = np.argmax(tf_model_classification_prediction, axis=1)[0]\n",
        "\n",
        "# Output predicted class\n",
        "print(f\"Predicted Class: {iris.target_names[predicted_class]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai-environment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
