{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbb6b31",
   "metadata": {},
   "source": [
    "In this technical lesson, we'll walk through the process of building a text classification model using Naive Bayes, extending our approach to include word embeddings for comparison with traditional vectorization techniques. We'll follow the established process of:\n",
    "\n",
    "1. problem definition\n",
    "2. preprocessing\n",
    "3. feature extraction\n",
    "4. model selection\n",
    "5. training, and evaluation\n",
    "\n",
    "Customer support departments often receive hundreds or thousands of tickets daily that need to be routed to the correct team. Manually sorting these tickets is time-consuming and prone to error. By automating this classification process, we can significantly reduce response times and ensure that customer issues are handled by the right specialists.\n",
    "\n",
    "We'll implement a Multinomial Naive Bayes classifier, which is particularly well-suited for text classification tasks due to its ability to work with the discrete features created by text vectorization. \n",
    "\n",
    "We'll also explore how modern word embeddings can provide an alternative feature representation that captures semantic relationships between words. \n",
    "\n",
    "Throughout this lesson, you'll learn how to transform raw text into numerical features using different approaches and build probabilistic models that can automatically categorize new text based on patterns learned from labeled examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "838449c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
