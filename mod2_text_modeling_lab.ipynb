{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Modeling with Naive Bayes Lab\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "You've recently joined UrbanTech, a company that develops software for urban transportation systems. As a junior data scientist on the customer experience team, you've been tasked with improving how the company handles user feedback from their mobile app.\n",
    "\n",
    "UrbanTech has a popular transit navigation app that helps users plan trips using public transportation. The app receives hundreds of user feedback messages daily through its in-app feedback form. Currently, these messages are manually sorted and routed to different teams - a time-consuming process that delays response times and creates inconsistent categorization.\n",
    "\n",
    "Your manager has asked you to develop a text classification system that can automatically categorize incoming feedback messages into three departments:\n",
    "1. **Navigation Issues** - Problems with directions, routes, or maps\n",
    "2. **Service Updates** - Feedback about transit service information accuracy\n",
    "3. **App Experience** - Issues with the app's functionality or user interface\n",
    "\n",
    "By implementing an effective text classification model, you'll help UrbanTech respond to user feedback more quickly and consistently, improving both internal efficiency and user satisfaction. You'll focus on using Naive Bayes, a powerful yet interpretable algorithm that works well with limited training data.\n",
    "\n",
    "## The Process\n",
    "\n",
    "In this lab, you'll follow these steps to build a text classification system:\n",
    "1. Data Loading and Exploration\n",
    "2. Text Preprocessing\n",
    "3. Feature Extraction\n",
    "4. Model Building with Naive Bayes\n",
    "5. Model Evaluation and Comparison\n",
    "6. Model Improvement\n",
    "7. Building a Prediction Function\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup - Import Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our text classification lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "# For text preprocessing and feature extraction\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# For modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Exploration\n",
    "\n",
    "Let's load the dataset of user feedback messages and explore its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Load the feedback data\n",
    "feedback_data = pd.read_csv('urban_feedback.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "feedback_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Basic information about the dataset\n",
    "print(f\"Dataset shape: {feedback_data.shape}\")\n",
    "print(\"\\nColumn information:\")\n",
    "feedback_data.info()\n",
    "print(f\"\\nCategory distribution:\\n{feedback_data['department'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "# Calculate text length\n",
    "feedback_data['text_length'] = None\n",
    "\n",
    "# Calculate basic statistics of text length by department - hint - use groupby and .describe()\n",
    "text_length_stats = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Display the statistics\n",
    "print(\"Text length statistics by department:\")\n",
    "print(text_length_stats)\n",
    "\n",
    "# Visualize text length by department\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='department', y='text_length', data=feedback_data, hue='department', legend=False)\n",
    "plt.title('Feedback Message Length by Department', fontsize=14)\n",
    "plt.xlabel('Department', fontsize=12)\n",
    "plt.ylabel('Text Length (characters)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at some example feedback messages from each department to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Display examples from each department\n",
    "for dept in feedback_data['department'].unique():\n",
    "    print(f\"\\nExamples of {dept} feedback:\")\n",
    "    examples = feedback_data[feedback_data['department'] == dept]['feedback_text'].sample(3, random_state=42).values\n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"{i}. {example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Text Preprocessing\n",
    "\n",
    "Now, let's create functions to preprocess the text data. This will involve cleaning the text and standardizing it for better feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing punctuation and special characters\n",
    "    - Removing numbers\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The text to clean\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Cleaned text\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = None\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = None\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Helper function for lemmatization with POS tagging\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Convert NLTK POS tags to WordNet POS tags\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text, remove stopwords, and lemmatize tokens.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The text to process\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of processed tokens\n",
    "    \"\"\"\n",
    "    # Initialize lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Get stopwords\n",
    "    stop_words = None\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = None\n",
    "    \n",
    "    # Tag tokens with parts of speech\n",
    "    tokens_tagged = None\n",
    "    \n",
    "    # Convert to WordNet POS tags\n",
    "    pos_tokens = None\n",
    "    # # Remove stopwords and lemmatize\n",
    "    processed_tokens = None\n",
    "    \n",
    "    return processed_tokens\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline: clean, tokenize, lemmatize, and rejoin.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The raw text to process\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Fully processed text\n",
    "    \"\"\"\n",
    "      # Apply cleaning\n",
    "    cleaned_text = None\n",
    "    \n",
    "    # Apply tokenization and lemmatization\n",
    "    processed_tokens = None\n",
    "    \n",
    "    # Join tokens back into single text string\n",
    "    processed_text = None\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Test our preprocessing functions on a sample feedback message\n",
    "sample_text = feedback_data['feedback_text'].iloc[0]\n",
    "print(f\"Original text:\\n{sample_text}\")\n",
    "\n",
    "cleaned_text = clean_text(sample_text)\n",
    "print(f\"\\nCleaned text:\\n{cleaned_text}\")\n",
    "\n",
    "tokens = tokenize_and_lemmatize(cleaned_text)\n",
    "print(f\"\\nTokenized and lemmatized text:\\n{tokens}\")\n",
    "\n",
    "processed_text = preprocess_text(sample_text)\n",
    "print(f\"\\nFully preprocessed text:\\n{processed_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction\n",
    "\n",
    "Now, let's split our data into training and testing sets, and convert the text into numerical features using different vectorization approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "# Split the data into training and testing sets (80% train, 20% test, random_state=42, stratify based on department)\n",
    "X_train, X_test, y_train, y_test = None\n",
    "\n",
    "# Create and fit a Bag of Words vectorizer (preprocessor=preprocess_text, max_features=50)\n",
    "count_vectorizer = None\n",
    "X_train_counts = None\n",
    "\n",
    "# Create and fit a TF-IDF vectorizer (preprocessor=preprocess_text, max_features=50)\n",
    "tfidf_vectorizer = None\n",
    "X_train_tfidf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Confirm the split\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nClass distribution in testing set:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# Examine the vocabulary size for each vectorizer (should be 50)\n",
    "count_vocab_size = len(count_vectorizer.get_feature_names_out())\n",
    "tfidf_vocab_size = len(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(f\"Bag of Words vocabulary size: {count_vocab_size}\")\n",
    "print(f\"TF-IDF vocabulary size: {tfidf_vocab_size}\")\n",
    "\n",
    "# Examine the feature matrices\n",
    "print(f\"\\nBag of Words feature matrix shape: {X_train_counts.shape}\")\n",
    "print(f\"TF-IDF feature matrix shape: {X_train_tfidf.shape}\")\n",
    "\n",
    "# Show the first few feature names\n",
    "print(f\"\\nSample of feature names: {count_vectorizer.get_feature_names_out()[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Building with Naive Bayes\n",
    "\n",
    "Now, let's build Multinomial Naive Bayes classifiers using both feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "# Create and train a Multinomial Naive Bayes model with Bag of Words features\n",
    "nb_bow = None\n",
    "None\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes model with TF-IDF features\n",
    "nb_tfidf = None\n",
    "None\n",
    "\n",
    "# Function to display the most informative features for each class\n",
    "def display_top_features(classifier, vectorizer, class_labels, n=5):\n",
    "    \"\"\"\n",
    "    Display the top n most informative features for each class.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    classifier : MultinomialNB\n",
    "        Trained Naive Bayes classifier\n",
    "    vectorizer : CountVectorizer or TfidfVectorizer\n",
    "        Fitted vectorizer used to transform the training data\n",
    "    class_labels : array-like\n",
    "        List of class labels\n",
    "    n : int, default=5\n",
    "        Number of top features to display per class\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping class labels to top features\n",
    "    \"\"\"\n",
    "    # Get feature names\n",
    "    feature_names = None\n",
    "    \n",
    "    top_features = {}\n",
    "    \n",
    "    # For each class, find the features with highest log probability\n",
    "    for i, label in enumerate(class_labels):\n",
    "        # Sort indices by feature log probability\n",
    "        top_indices = None\n",
    "        \n",
    "        # Get the feature names\n",
    "        top_features[label] = None\n",
    "        \n",
    "        # Print the top features\n",
    "        print(f\"\\nTop {n} features for class '{label}':\")\n",
    "        for rank, feature in enumerate(top_features[label], 1):\n",
    "            print(f\"{rank}. {feature}\")\n",
    "    \n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Display top features for the Bag of Words model\n",
    "print(\"Top features from Bag of Words model:\")\n",
    "bow_top_features = display_top_features(nb_bow, count_vectorizer, nb_bow.classes_)\n",
    "\n",
    "# Display top features for the TF-IDF model\n",
    "print(\"\\nTop features from TF-IDF model:\")\n",
    "tfidf_top_features = display_top_features(nb_tfidf, tfidf_vectorizer, nb_tfidf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Evaluation and Comparison\n",
    "\n",
    "Let's evaluate our models on the test set and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "# Transform the test data with both vectorizers\n",
    "X_test_counts = None\n",
    "X_test_tfidf = None\n",
    "\n",
    "# Predict on the test data with both models\n",
    "y_pred_bow = None\n",
    "y_pred_tfidf = None\n",
    "\n",
    "# Function to evaluate a model and display results\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model and display its performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True class labels\n",
    "    y_pred : array-like\n",
    "        Predicted class labels\n",
    "    model_name : str\n",
    "        Name of the model being evaluated\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Accuracy score\n",
    "    \"\"\"\n",
    "    # Calculate accuracy\n",
    "    accuracy = None\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(f\"Evaluation for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Generate and print classification report\n",
    "    report = None\n",
    "    print(f\"\\nClassification Report:\\n{report}\")\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Evaluate both models\n",
    "bow_accuracy = evaluate_model(y_test, y_pred_bow, \"Bag of Words + Naive Bayes\")\n",
    "tfidf_accuracy = evaluate_model(y_test, y_pred_tfidf, \"TF-IDF + Naive Bayes\")\n",
    "\n",
    "# Create confusion matrices for both models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion matrix for Bag of Words model\n",
    "cm_bow = confusion_matrix(y_test, y_pred_bow)\n",
    "sns.heatmap(cm_bow, annot=True, fmt='d', cmap='Blues', xticklabels=nb_bow.classes_, \n",
    "            yticklabels=nb_bow.classes_, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Bag of Words Model', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=10)\n",
    "axes[0].set_ylabel('True Label', fontsize=10)\n",
    "\n",
    "# Confusion matrix for TF-IDF model\n",
    "cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
    "sns.heatmap(cm_tfidf, annot=True, fmt='d', cmap='Blues', xticklabels=nb_tfidf.classes_, \n",
    "            yticklabels=nb_tfidf.classes_, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - TF-IDF Model', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=10)\n",
    "axes[1].set_ylabel('True Label', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare model accuracies\n",
    "models = ['Bag of Words + Naive Bayes', 'TF-IDF + Naive Bayes']\n",
    "accuracies = [bow_accuracy, tfidf_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=models, y=accuracies)\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "# Add accuracy labels to the bars\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.4f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Improvement\n",
    "\n",
    "Let's try to improve the better model (TF-IDF) by tuning the hyperparameters and refining the feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "# Let's perform grid search to tune both vectorizer and model parameters together\n",
    "# Create a pipeline that combines vectorization and classification - name the steps 'vectorizer' and 'classifier' respectively\n",
    "text_clf = None\n",
    "\n",
    "# Define parameter grid to search\n",
    "# This includes parameters for both the vectorizer and the classifier\n",
    "param_grid = {\n",
    "    # Vectorizer type and parameters\n",
    "    'vectorizer': [count_vectorizer, tfidf_vectorizer],\n",
    "    \n",
    "    # Parameters for CountVectorizer and TfidfVectorizer\n",
    "    'vectorizer__max_features': [50, 100],\n",
    "    'vectorizer__min_df': [1, 2, 3],\n",
    "    'vectorizer__max_df': [0.85, 0.9, 0.95],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    \n",
    "    # Classifier parameters\n",
    "    'classifier__alpha': [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = None\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "None\n",
    "\n",
    "# Use the best estimator to make predictions on the test set\n",
    "best_model = None\n",
    "y_pred_grid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Evaluate the best model from grid search\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nBest Cross-Validation Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Evaluate the improved model\n",
    "improved_tfidf_accuracy = evaluate_model(y_test, y_pred_grid, \"Improved TF-IDF + Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Building a Prediction Function\n",
    "\n",
    "Finally, let's create a function that can take new feedback messages and classify them into the appropriate department. This would be the function that UrbanTech could integrate into their feedback processing system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with your code\n",
    "def classify_feedback(feedback_text):\n",
    "    \"\"\"\n",
    "    Classify a new feedback message into the appropriate department.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feedback_text : str\n",
    "        The raw feedback message to classify\n",
    "    model : classifier\n",
    "        Trained classification model\n",
    "    vectorizer : vectorizer\n",
    "        Fitted vectorizer to transform the text\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing classification results\n",
    "    \"\"\"\n",
    "    # Predict the department\n",
    "    department = None\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = None\n",
    "    \n",
    "    # Find the confidence (probability of the predicted class)\n",
    "    confidence = None\n",
    "    \n",
    "    # Create and return the result dictionary\n",
    "    result = {\n",
    "        'feedback_text': feedback_text,\n",
    "        'department': department,\n",
    "        'confidence': confidence,\n",
    "        'all_probabilities': dict(zip(best_model.classes_, probabilities[0]))\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "# Test the classification function with new feedback messages\n",
    "new_feedback = [\n",
    "    \"The app crashed when I tried to view the bus schedule.\",\n",
    "    \"Your subway arrival times were completely wrong! The train was 10 minutes late.\",\n",
    "    \"I love the new route planning feature, but the app is very slow to load maps.\",\n",
    "    \"Can you add more bike routes to the navigation options?\", \n",
    "    \"The bus schedule says the next bus is in 5 minutes, but it's already been 20 minutes and no bus.\"]\n",
    "\n",
    "for feedback in new_feedback:\n",
    "    result = classify_feedback(feedback)\n",
    "    \n",
    "    print(f'Feedback: {result['feedback_text']}')\n",
    "    print(f'Predicted Department: {result['department']}')\n",
    "    print(f'Confidence: {result['confidence']:.4f}')\n",
    "    \n",
    "    # Show all class probabilities\n",
    "    print('All department probabilities:')\n",
    "    for dept, prob in result['all_probabilities'].items():\n",
    "        print(f'  {dept}: {prob:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've successfully built a text classification system that can automatically categorize user feedback messages for UrbanTech's transit app. In this lab, you've learned how to:\n",
    "\n",
    "1. Preprocess text data to make it suitable for machine learning\n",
    "2. Extract features using different vectorization techniques (Bag of Words and TF-IDF)\n",
    "3. Build and train Multinomial Naive Bayes classifiers for text classification\n",
    "4. Evaluate and compare model performance using appropriate metrics\n",
    "5. Tune hyperparameters to improve model performance\n",
    "6. Create a practical classification function that could be integrated into a production system\n",
    "7. Package everything into a pipeline for easier deployment\n",
    "\n",
    "The classification system you've built could significantly improve UrbanTech's ability to handle user feedback efficiently, ensuring that issues are routed to the correct department for prompt resolution. This would enhance the user experience by enabling quicker response times and more consistent handling of feedback.\n",
    "\n",
    "Remember that in a real-world scenario, you would need to periodically retrain your model with new data to ensure it remains accurate as user feedback patterns change over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cohort_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
